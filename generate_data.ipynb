{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/arihantparsoya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from statistics import median, mean\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output # only for jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import game env\n",
    "from puzzle import GameGrid\n",
    "env = GameGrid()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0, 0, 0, 0]\n",
      "[2, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# display current state\n",
    "env.display_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Data\n",
    "To check if its working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_random_games_first():\n",
    "    # Each of these is its own game.\n",
    "    for episode in range(5):\n",
    "        env.reset()\n",
    "        # this is each frame, up to 200...but we wont make it that far.\n",
    "        for t in range(200):\n",
    "            # This will display the environment\n",
    "            # Only display if you really want to see it.\n",
    "            # Takes much longer to display it.\n",
    "            clear_output()\n",
    "            env.display_state()\n",
    "            \n",
    "            # This will just create a sample action in any environment.\n",
    "            # In this environment, the action can be 0 or 1, which is left or right\n",
    "            action = env.action_space()\n",
    "            \n",
    "            # this executes the environment with an action, \n",
    "            # and returns the observation of the environment, \n",
    "            # the reward, if the env is over, and other info.\n",
    "            \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4, 8, 16, 2]\n",
      "[32, 128, 8, 8]\n",
      "[4, 8, 64, 4]\n",
      "[2, 16, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "some_random_games_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_requirement = 16 # Save (state, action) pair only if score is higher than score_requirement\n",
    "initial_games = 100 # number of games played\n",
    "goal_steps = 1000 # number of steps in each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score: 11470.04\n",
      "Median score for accepted scores: 7624.0\n",
      "Counter({4972: 1, 9614: 1, 34830: 1, 7538: 1, 13420: 1, 4952: 1, 23636: 1, 7040: 1, 6834: 1, 13160: 1, 3968: 1, 9988: 1, 6276: 1, 3746: 1, 3046: 1, 3654: 1, 54452: 1, 14382: 1, 24646: 1, 4726: 1, 5294: 1, 17950: 1, 15938: 1, 10004: 1, 24598: 1, 14882: 1, 9374: 1, 4434: 1, 23388: 1, 520: 1, 9968: 1, 15558: 1, 11544: 1, 18732: 1, 11076: 1, 3758: 1, 4088: 1, 10070: 1, 5102: 1, 2436: 1, 12262: 1, 7004: 1, 5778: 1, 5862: 1, 18810: 1, 35746: 1, 9818: 1, 5022: 1, 3880: 1, 17042: 1, 6018: 1, 4742: 1, 5042: 1, 5130: 1, 4334: 1, 1674: 1, 13206: 1, 3270: 1, 15860: 1, 5342: 1, 10090: 1, 15858: 1, 4958: 1, 11758: 1, 44238: 1, 7492: 1, 14486: 1, 5044: 1, 4982: 1, 45816: 1, 26186: 1, 17006: 1, 3748: 1, 5792: 1, 5940: 1, 21482: 1, 9894: 1, 29470: 1, 6812: 1, 11036: 1, 4860: 1, 3886: 1, 2794: 1, 7038: 1, 15166: 1, 34906: 1, 7710: 1, 4548: 1, 9994: 1, 3556: 1, 6062: 1, 5806: 1, 9626: 1, 5386: 1, 10234: 1, 5288: 1, 9150: 1, 4904: 1, 22324: 1, 12242: 1})\n"
     ]
    }
   ],
   "source": [
    "def initial_population():\n",
    "    # [OBS, MOVES]\n",
    "    training_data = []\n",
    "    # all scores:\n",
    "    scores = []\n",
    "    # just the scores that met our threshold:\n",
    "    accepted_scores = []\n",
    "    # iterate through however many games we want:\n",
    "    for _ in range(initial_games):\n",
    "        score = 0\n",
    "        # moves specifically from this environment:\n",
    "        game_memory = []\n",
    "        # previous observation that we saw\n",
    "        prev_observation = []\n",
    "        # for each frame in 200\n",
    "        for _ in range(goal_steps):\n",
    "            # choose random action (0 or 1)\n",
    "            action = env.action_space()\n",
    "            # do it!\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # notice that the observation is returned FROM the action\n",
    "            # so we'll store the previous observation here, pairing\n",
    "            # the prev observation to the action we'll take.\n",
    "            if len(prev_observation) > 0 :\n",
    "                game_memory.append([prev_observation, action])\n",
    "            prev_observation = observation\n",
    "            score+=reward\n",
    "            if done: break\n",
    "\n",
    "        # IF our score is higher than our threshold, we'd like to save\n",
    "        # every move we made\n",
    "        # NOTE the reinforcement methodology here. \n",
    "        # all we're doing is reinforcing the score, we're not trying \n",
    "        # to influence the machine in any way as to HOW that score is \n",
    "        # reached.\n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:\n",
    "                # Create one hor vector for actions\n",
    "                # [\"'w'\", \"'s'\", \"'d'\", \"'a'\"] === [UP, DOWN, RIGHT, LEFT]\n",
    "                if data[1] == \"'w'\":\n",
    "                    output = [1,0,0,0]\n",
    "                elif data[1] == \"'s'\":\n",
    "                    output = [0,1,0,0]\n",
    "                elif data[1] == \"'d'\":\n",
    "                    output = [0,0,1,0]\n",
    "                elif data[1] == \"'a'\":\n",
    "                    output = [0,0,0,1]\n",
    "                    \n",
    "                # saving our training data\n",
    "                training_data.append([data[0], output])\n",
    "\n",
    "        # reset env to play again\n",
    "        env.reset()\n",
    "        # save overall scores\n",
    "        scores.append(score)\n",
    "    \n",
    "    # just in case you wanted to reference later\n",
    "    training_data_save = np.array(training_data)\n",
    "    np.save('data/saved.npy',training_data_save)\n",
    "    \n",
    "    # some stats here, to further illustrate the neural network magic!\n",
    "    print('Average accepted score:',mean(accepted_scores))\n",
    "    print('Median score for accepted scores:',median(accepted_scores))\n",
    "    print(Counter(accepted_scores))\n",
    "    \n",
    "    return\n",
    "\n",
    "initial_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
