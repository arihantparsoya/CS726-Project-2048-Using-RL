{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"data/saved.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "        list([0, 1, 0, 0])],\n",
       "       [list([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0]),\n",
       "        list([1, 0, 0, 0])],\n",
       "       [list([4, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "        list([0, 0, 1, 0])],\n",
       "       ...,\n",
       "       [list([32, 4, 2, 2, 2, 8, 64, 8, 16, 4, 32, 16, 4, 8, 4, 2]),\n",
       "        list([0, 0, 1, 0])],\n",
       "       [list([2, 32, 4, 4, 2, 8, 64, 8, 16, 4, 32, 16, 4, 8, 4, 2]),\n",
       "        list([0, 0, 0, 1])],\n",
       "       [list([2, 32, 8, 2, 2, 8, 64, 8, 16, 4, 32, 16, 4, 8, 4, 2]),\n",
       "        list([0, 1, 0, 0])]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/arihantparsoya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from statistics import median, mean\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import game env\n",
    "from puzzle import GameGrid\n",
    "env = GameGrid()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(input_size):\n",
    "\n",
    "    network = input_data(shape=[None, input_size, 1], name='input')\n",
    "\n",
    "    network = fully_connected(network, 200, activation='relu')\n",
    "    #network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 100, activation='relu')\n",
    "    #network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 4, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, model=False):\n",
    "\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)\n",
    "    y = [i[1] for i in training_data]\n",
    "\n",
    "    if not model:\n",
    "        model = neural_network_model(input_size = len(X[0]))\n",
    "    \n",
    "    model.fit({'input': X}, {'targets': y}, n_epoch=2, batch_size=10, snapshot_step=10, show_metric=True, run_id='openai_learning')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 317637  | total loss: \u001b[1m\u001b[32m1.39146\u001b[0m\u001b[0m | time: 714.868s\n",
      "| Adam | epoch: 002 | loss: 1.39146 - acc: 0.2126 -- iter: 1588180/1588188\n",
      "Training Step: 317638  | total loss: \u001b[1m\u001b[32m1.39074\u001b[0m\u001b[0m | time: 714.872s\n",
      "| Adam | epoch: 002 | loss: 1.39074 - acc: 0.2213 -- iter: 1588188/1588188\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = train_model(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "num_games = 1000\n",
    "goal_steps = 200\n",
    "rewards = []\n",
    "choices = []\n",
    "accepted_scores = []\n",
    "\n",
    "for each_game in range(num_games):\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        #env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,4)\n",
    "        else:\n",
    "            action = np.argmax(model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0]).item()\n",
    "                \n",
    "        choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        new_observation = np.array(np.array(new_observation).flatten().tolist())\n",
    "        \n",
    "        prev_obs = new_observation\n",
    "        game_memory.append([new_observation, action])\n",
    "        \n",
    "        score+=reward\n",
    "        if done: break\n",
    "        \n",
    "    if each_game%100 == 0: print(each_game)\n",
    "    rewards.append(score)\n",
    "    accepted_scores.append(env.highest_score())\n",
    "\n",
    "print('Average Score:',sum(rewards)/len(rewards))\n",
    "print('choice 0:{} choice 1:{} choice 2:{} choice 3:{}'.format(choices.count(0)/len(choices),choices.count(1)/len(choices), choices.count(2)/len(choices), choices.count(3)/len(choices)))\n",
    "print(Counter(accepted_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
